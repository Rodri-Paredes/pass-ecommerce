# üéØ Prompt para Optimizaci√≥n del ERP - PASS Clothing

## üìã Contexto del Sistema Actual

Tenemos un e-commerce de ropa (PASS Clothing) que consume datos de un ERP a trav√©s de Supabase. Actualmente enfrentamos:

- ‚ùå Demasiadas llamadas API por cada request del frontend
- ‚ùå Im√°genes pesadas sin optimizaci√≥n
- ‚ùå Queries N+1 al cargar productos con variantes y stock
- ‚ùå Sin √≠ndices optimizados en tablas cr√≠ticas
- ‚ùå Sin vistas materializadas para queries frecuentes
- ‚ùå Sin CDN para im√°genes

---

## üöÄ Prompt para el Equipo del ERP

**Asunto:** Optimizaciones Backend Requeridas para Mejora de Performance Web

**Para:** Equipo de Desarrollo ERP / Base de Datos

---

### 1. OPTIMIZACI√ìN DE IM√ÅGENES (CR√çTICO)

**Problema actual:**
Las im√°genes se almacenan en alta resoluci√≥n (~2-5 MB cada una) y se sirven directamente al frontend sin procesamiento.

**Soluci√≥n requerida:**
```
Implementar sistema de im√°genes multi-resoluci√≥n:

1. Al subir imagen al ERP, generar autom√°ticamente 4 versiones:
   - thumbnail:  200x200px,  ~20 KB  (para grids/listados)
   - small:      400x400px,  ~50 KB  (para cards en mobile)
   - medium:     800x800px,  ~150 KB (para detalles de producto)
   - large:      1600x1600px, ~400 KB (para zoom/fullscreen)

2. Formato: Convertir a WebP (mejor compresi√≥n) con fallback JPG
   
3. Estructura en Supabase Storage:
   /products/{product_id}/thumbnail.webp
   /products/{product_id}/small.webp
   /products/{product_id}/medium.webp
   /products/{product_id}/large.webp
   /products/{product_id}/original.jpg (backup)

4. Campo en tabla products:
   ALTER TABLE products ADD COLUMN image_urls JSONB DEFAULT '{
     "thumbnail": "https://...",
     "small": "https://...",
     "medium": "https://...",
     "large": "https://...",
     "original": "https://..."
   }'::jsonb;

5. API: Al consultar productos, devolver solo thumbnail/small por defecto
   Endpoint separado para im√°genes grandes bajo demanda
```

**Impacto esperado:** -85% en peso de im√°genes, -70% en tiempo de carga

---

### 2. OPTIMIZACI√ìN DE QUERIES (CR√çTICO)

**Problema actual:**
Query N+1: Para cargar 12 productos hacemos 1 + 12 + 24 queries (productos + variantes + stock)

**Soluci√≥n requerida:**
```sql
-- Crear vista materializada que pre-calcula stock total
CREATE MATERIALIZED VIEW products_with_stock AS
SELECT 
  p.id,
  p.name,
  p.description,
  p.category,
  p.image_url,
  p.created_at,
  COALESCE(SUM(s.quantity), 0) as total_stock,
  json_agg(
    json_build_object(
      'size', v.size,
      'stock', COALESCE(SUM(s.quantity), 0),
      'branches', json_agg(
        json_build_object(
          'city', s.city,
          'quantity', s.quantity
        )
      )
    )
  ) as variants_summary
FROM products p
LEFT JOIN variants v ON v.product_id = p.id
LEFT JOIN stock s ON s.variant_id = v.id
GROUP BY p.id, p.name, p.description, p.category, p.image_url, p.created_at;

-- Refrescar cada 5 minutos (o en tiempo real con triggers)
CREATE EXTENSION IF NOT EXISTS pg_cron;
SELECT cron.schedule('refresh-products-stock', '*/5 * * * *', 
  'REFRESH MATERIALIZED VIEW CONCURRENTLY products_with_stock'
);

-- √çndices para b√∫squedas r√°pidas
CREATE INDEX idx_products_stock_category ON products_with_stock(category);
CREATE INDEX idx_products_stock_created ON products_with_stock(created_at DESC);
CREATE INDEX idx_products_stock_total ON products_with_stock(total_stock) 
  WHERE total_stock > 0;
```

**Endpoint API mejorado:**
```sql
-- En lugar de hacer 37 queries, hacer 1 query:
SELECT * FROM products_with_stock 
WHERE category = 'Hoodies' 
  AND total_stock > 0
ORDER BY created_at DESC
LIMIT 12;
```

**Impacto esperado:** -97% queries (de 37 a 1), respuesta 10x m√°s r√°pida

---

### 3. √çNDICES DE BASE DE DATOS (ALTO IMPACTO)

**Problema actual:**
Queries lentas en b√∫squedas, filtros y ordenamiento.

**Soluci√≥n requerida:**
```sql
-- Productos
CREATE INDEX idx_products_category ON products(category);
CREATE INDEX idx_products_created_desc ON products(created_at DESC);
CREATE INDEX idx_products_name_gin ON products USING gin(to_tsvector('spanish', name));
CREATE INDEX idx_products_active ON products(status) WHERE status = 'ACTIVO';

-- Variantes
CREATE INDEX idx_variants_product ON variants(product_id);
CREATE INDEX idx_variants_size ON variants(size);
CREATE INDEX idx_variants_composite ON variants(product_id, size);

-- Stock
CREATE INDEX idx_stock_variant ON stock(variant_id);
CREATE INDEX idx_stock_city ON stock(city);
CREATE INDEX idx_stock_quantity ON stock(quantity) WHERE quantity > 0;
CREATE INDEX idx_stock_composite ON stock(variant_id, city);

-- Drops
CREATE INDEX idx_drops_status ON drops(status) WHERE status = 'ACTIVO';
CREATE INDEX idx_drops_date ON drops(release_date DESC);

-- √ìrdenes (si existen)
CREATE INDEX idx_orders_user ON orders(user_id);
CREATE INDEX idx_orders_status ON orders(status);
CREATE INDEX idx_orders_date ON orders(created_at DESC);
CREATE INDEX idx_orders_composite ON orders(user_id, status, created_at DESC);
```

**Verificar √≠ndices existentes:**
```sql
SELECT tablename, indexname, indexdef 
FROM pg_indexes 
WHERE schemaname = 'public'
ORDER BY tablename, indexname;
```

**Impacto esperado:** Queries 5-10x m√°s r√°pidas en filtros/b√∫squedas

---

### 4. CACH√â EN EL ERP (MEDIO IMPACTO)

**Problema actual:**
Cada request del frontend golpea la base de datos directamente.

**Soluci√≥n requerida:**
```
Implementar Redis como capa de cach√©:

1. Cachear queries frecuentes:
   - Lista de productos por categor√≠a: TTL 5 minutos
   - Detalles de producto: TTL 10 minutos
   - Stock por sucursal: TTL 2 minutos
   - Drops activos: TTL 15 minutos

2. Invalidaci√≥n inteligente:
   - Al crear/editar producto ‚Üí invalidar cache de esa categor√≠a
   - Al actualizar stock ‚Üí invalidar cache de ese producto
   - Al cambiar status de drop ‚Üí invalidar cache de drops

3. Estructura de keys:
   products:category:{category}:page:{page}
   product:detail:{product_id}
   product:stock:{product_id}
   drops:active
   
4. Ejemplo implementaci√≥n (Node.js):
   const redis = require('redis');
   const client = redis.createClient();
   
   async function getProducts(category) {
     const cacheKey = `products:category:${category}`;
     const cached = await client.get(cacheKey);
     
     if (cached) return JSON.parse(cached);
     
     const data = await db.query('SELECT * FROM products WHERE category = $1', [category]);
     await client.setEx(cacheKey, 300, JSON.stringify(data)); // 5 min
     
     return data;
   }
```

**Impacto esperado:** -80% carga en base de datos, respuestas instant√°neas

---

### 5. API OPTIMIZADA (ALTO IMPACTO)

**Problema actual:**
Frontend hace m√∫ltiples requests para obtener datos relacionados.

**Soluci√≥n requerida:**
```
Crear endpoints agregados que devuelvan todo lo necesario en 1 request:

1. GET /api/products/catalog
   Query params: ?category=Hoodies&page=1&limit=12&sort=newest
   
   Response:
   {
     "products": [
       {
         "id": "...",
         "name": "Hoodie B√°sico",
         "price": 250,
         "image_urls": {
           "thumbnail": "https://...",
           "small": "https://..."
         },
         "total_stock": 45,
         "available_sizes": ["S", "M", "L", "XL"],
         "is_new": true,
         "drop": {
           "id": "...",
           "name": "Summer 2025"
         }
       }
     ],
     "pagination": {
       "total": 120,
       "page": 1,
       "pages": 10
     },
     "filters": {
       "categories": ["Hoodies", "Pantalones", "Poleras"],
       "sizes": ["XS", "S", "M", "L", "XL"],
       "price_range": { "min": 150, "max": 450 }
     }
   }

2. GET /api/products/:id/full
   Devuelve producto + todas las variantes + stock por sucursal + drop asociado
   
3. GET /api/drops/active
   Devuelve drops activos con productos incluidos (eager loading)

4. Implementar paginaci√≥n cursor-based (m√°s eficiente):
   GET /api/products?cursor=eyJpZCI6...&limit=12
   
   En lugar de:
   GET /api/products?page=5&limit=12  ‚Üê Ineficiente en p√°ginas altas
```

**Impacto esperado:** -90% requests del frontend, UX m√°s fluida

---

### 6. CDN PARA ASSETS (CR√çTICO)

**Problema actual:**
Im√°genes se sirven directamente desde Supabase Storage (lento, caro).

**Soluci√≥n requerida:**
```
Configurar Cloudflare CDN o Cloudinary:

Opci√≥n A - Cloudflare (gratis):
1. Proxy de Supabase Storage a trav√©s de Cloudflare
2. Cache autom√°tico de im√°genes
3. Compresi√≥n autom√°tica
4. WebP/AVIF autom√°tico seg√∫n browser

Opci√≥n B - Cloudinary (mejor, pero pago):
1. Migrar im√°genes a Cloudinary
2. URLs transformables on-the-fly:
   https://res.cloudinary.com/passstreetwear/image/upload/
     w_400,h_400,c_fill,f_auto,q_auto/
     product-abc123.jpg
   
3. Transformaciones autom√°ticas:
   - f_auto: Formato autom√°tico (WebP si soportado)
   - q_auto: Calidad autom√°tica seg√∫n red
   - w_400: Resize on-demand
   
4. Cach√© global en +200 ubicaciones

Configuraci√≥n Supabase + Cloudflare:
1. En panel de Supabase: Settings ‚Üí Storage ‚Üí Enable CDN
2. Configurar CNAME: cdn.passstreetwear.com ‚Üí supabase-cdn.com
3. Cache-Control headers: max-age=31536000 (1 a√±o)
```

**Impacto esperado:** -70% tiempo de carga de im√°genes, menor costo

---

### 7. MONITOREO Y LOGS (RECOMENDADO)

**Problema actual:**
No sabemos qu√© queries son lentas ni cu√°ntas veces se ejecutan.

**Soluci√≥n requerida:**
```sql
-- Activar logging de queries lentas en PostgreSQL
ALTER SYSTEM SET log_min_duration_statement = 100; -- 100ms
ALTER SYSTEM SET log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d ';
ALTER SYSTEM SET log_statement = 'all';
SELECT pg_reload_conf();

-- Ver queries m√°s lentas
SELECT 
  query,
  calls,
  total_time,
  mean_time,
  max_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 20;

-- Instalar extensi√≥n para estad√≠sticas
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
```

**Herramientas recomendadas:**
- **Supabase Dashboard:** Ver queries lentas en "Database" ‚Üí "Query Performance"
- **pgAnalyze:** Servicio externo para an√°lisis profundo
- **DataDog/NewRelic:** APM para monitoreo en tiempo real

---

### 8. COMPRESI√ìN DE RESPUESTAS (BAJO ESFUERZO, ALTO IMPACTO)

**Problema actual:**
Respuestas JSON grandes sin comprimir.

**Soluci√≥n requerida:**
```javascript
// En servidor Node.js/Express
const compression = require('compression');
app.use(compression({
  level: 6, // Balance entre compresi√≥n y CPU
  threshold: 1024, // Solo comprimir > 1KB
  filter: (req, res) => {
    if (req.headers['x-no-compression']) return false;
    return compression.filter(req, res);
  }
}));

// Configurar headers
res.setHeader('Content-Encoding', 'gzip');
res.setHeader('Vary', 'Accept-Encoding');
```

**Impacto esperado:** -70% tama√±o de respuestas JSON

---

### 9. RATE LIMITING (SEGURIDAD + PERFORMANCE)

**Problema actual:**
Sin protecci√≥n contra abuso de API.

**Soluci√≥n requerida:**
```javascript
const rateLimit = require('express-rate-limit');

// Rate limit general
const apiLimiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutos
  max: 100, // 100 requests por IP
  message: 'Demasiadas peticiones, intenta de nuevo en 15 minutos'
});

// Rate limit para b√∫squedas (m√°s restrictivo)
const searchLimiter = rateLimit({
  windowMs: 1 * 60 * 1000, // 1 minuto
  max: 20, // 20 b√∫squedas por minuto
});

app.use('/api/', apiLimiter);
app.use('/api/products/search', searchLimiter);
```

---

### 10. PAGINACI√ìN CURSOR-BASED (RECOMENDADO)

**Problema actual:**
`OFFSET` es ineficiente en p√°ginas altas (p√°gina 100 = skip 1200 rows).

**Soluci√≥n requerida:**
```sql
-- Mal (OFFSET - lento en p√°ginas altas):
SELECT * FROM products 
WHERE category = 'Hoodies'
ORDER BY created_at DESC
LIMIT 12 OFFSET 120;  -- P√°gina 10: Lee 132 rows, devuelve 12

-- Bien (Cursor - siempre r√°pido):
SELECT * FROM products 
WHERE category = 'Hoodies'
  AND created_at < '2025-11-01T00:00:00Z'  -- Cursor de la p√°gina anterior
ORDER BY created_at DESC
LIMIT 12;  -- Lee solo 12 rows

-- API endpoint:
GET /api/products?category=Hoodies&cursor=2025-11-01T00:00:00Z&limit=12

Response:
{
  "products": [...],
  "next_cursor": "2025-10-15T10:30:00Z",
  "has_more": true
}
```

---

## üìä PRIORIZACI√ìN (Esfuerzo vs Impacto)

### üî¥ CR√çTICO - Implementar Primero (Semana 1)
1. ‚úÖ Vista materializada `products_with_stock` ‚Üí -97% queries
2. ‚úÖ √çndices en tablas principales ‚Üí 5-10x m√°s r√°pido
3. ‚úÖ CDN para im√°genes (Cloudflare) ‚Üí -70% tiempo carga

**Impacto:** -80% en tiempo de respuesta API

### üü° IMPORTANTE - Implementar Despu√©s (Semana 2)
4. ‚úÖ Sistema multi-resoluci√≥n de im√°genes ‚Üí -85% peso
5. ‚úÖ Endpoints agregados optimizados ‚Üí -90% requests frontend
6. ‚úÖ Compresi√≥n Gzip en respuestas ‚Üí -70% tama√±o payloads

**Impacto:** -60% en tiempo de carga total

### üü¢ RECOMENDADO - Implementar Luego (Semana 3-4)
7. ‚úÖ Redis para cach√© ‚Üí -80% carga DB
8. ‚úÖ Paginaci√≥n cursor-based ‚Üí Mejor en listados largos
9. ‚úÖ Rate limiting ‚Üí Protecci√≥n y estabilidad
10. ‚úÖ Monitoreo con pg_stat_statements ‚Üí Visibilidad

**Impacto:** +20% mejora adicional + mejor observabilidad

---

## üß™ TESTING DE OPTIMIZACIONES

### Benchmark Actual (Antes)
```bash
# Query de productos con variantes y stock
Time: 450ms (promedio)
Queries ejecutadas: 37
Tama√±o respuesta: 850 KB

# Query con imagen original
Time: 2.3s (carga completa)
Imagen: 3.5 MB
```

### Benchmark Esperado (Despu√©s)
```bash
# Con vista materializada + √≠ndices
Time: 45ms (-90%)
Queries ejecutadas: 1 (-97%)
Tama√±o respuesta (gzip): 120 KB (-86%)

# Con CDN + multi-resoluci√≥n
Time: 350ms (-85%)
Imagen (thumbnail): 20 KB (-99%)
```

### C√≥mo Medir
```sql
-- Ver tiempo de query actual
EXPLAIN ANALYZE
SELECT * FROM products 
WHERE category = 'Hoodies'
LIMIT 12;

-- Comparar con vista materializada
EXPLAIN ANALYZE
SELECT * FROM products_with_stock
WHERE category = 'Hoodies'
LIMIT 12;
```

---

## üìù CHECKLIST DE ENTREGA

Antes de considerar completa la optimizaci√≥n:

- [ ] Vista materializada `products_with_stock` creada y programada
- [ ] 15+ √≠ndices creados en tablas cr√≠ticas
- [ ] Sistema multi-resoluci√≥n de im√°genes implementado
- [ ] CDN configurado (Cloudflare o Cloudinary)
- [ ] Endpoints agregados `/catalog`, `/products/:id/full`
- [ ] Compresi√≥n Gzip activada en API
- [ ] Redis configurado para cach√© (opcional pero recomendado)
- [ ] Rate limiting implementado
- [ ] Monitoreo de queries lentas activo
- [ ] Documentaci√≥n de nuevos endpoints
- [ ] Testing de performance antes/despu√©s

---

## üéØ M√âTRICAS DE √âXITO

### KPIs a Medir
```
Query Response Time:     450ms ‚Üí 45ms  (‚úÖ -90%)
Database Load:           100% ‚Üí 20%    (‚úÖ -80%)
API Response Size:       850KB ‚Üí 120KB (‚úÖ -86%)
Image Load Time:         2.3s ‚Üí 350ms  (‚úÖ -85%)
Requests per Page Load:  37 ‚Üí 3        (‚úÖ -92%)
```

### Objetivo Final
```
‚úÖ Lighthouse Performance:  78 ‚Üí 95+
‚úÖ LCP (Largest Contentful Paint): 2.8s ‚Üí <1.2s
‚úÖ Costo Supabase: $200/mes ‚Üí $50/mes (-75%)
‚úÖ Tasa de conversi√≥n: +20-30% (p√°ginas r√°pidas)
```

---

## üìû CONTACTO Y SEGUIMIENTO

**Requester:** Equipo Frontend PASS Clothing  
**Fecha l√≠mite:** 2 semanas (prioridades cr√≠ticas)  
**Reuni√≥n de seguimiento:** Cada viernes para revisar progreso  

**Preguntas t√©cnicas:**
- Slack: #backend-optimization
- Email: dev@passstreetwear.com

---

## üîó REFERENCIAS √öTILES

- [Supabase Performance Best Practices](https://supabase.com/docs/guides/platform/performance)
- [PostgreSQL Indexing Strategies](https://www.postgresql.org/docs/current/indexes.html)
- [Redis Caching Patterns](https://redis.io/docs/manual/patterns/)
- [Cloudinary Image Optimization](https://cloudinary.com/documentation/image_optimization)
- [Database View Materialization](https://www.postgresql.org/docs/current/sql-creatematerializedview.html)

---

**¬øDudas sobre alguna optimizaci√≥n?** Disponible para reuni√≥n t√©cnica para explicar implementaci√≥n detallada.
